{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Framework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimanh22/706_Assignments/blob/main/Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WigneUJ7g2J"
      },
      "source": [
        "# **GLoVE+BiLSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBLGq3tsHaZK",
        "outputId": "984139b7-bba8-4c52-b3b8-023acc240f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install keras\n",
        "!pip install emoji --upgrade\n",
        "!pip install keras-self-attention\n",
        "!pip install wordninja"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
            "Requirement already up-to-date: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.47.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-self-attention) (1.15.0)\n",
            "Requirement already satisfied: wordninja in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaDxi6vN8yil"
      },
      "source": [
        "# **Headers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcKlqkNXGbut"
      },
      "source": [
        "##################Headers#########\n",
        "import pandas as pd\n",
        "import keras\n",
        "import emoji\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input\n",
        "from keras.layers import LSTM, Bidirectional, Dropout\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnECRf1Y89QB"
      },
      "source": [
        "# **Loading the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r5Wv9y0Gtcm",
        "outputId": "a58077b7-7948-40c6-f9ad-4e5808223282",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2bc135a1-cd46-4513-80b4-24a4eb82fb86\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2bc135a1-cd46-4513-80b4-24a4eb82fb86\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ISEAR.csv to ISEAR (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCxGj6cqoEZe"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"ISEAR.csv\",names=[\"emotion\",\"text\",\"\"])\n",
        "df_train=df[[\"text\",\"emotion\"]]\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "#df_train,df_test=train_test_split(df, test_size=0.3, random_state=42)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3_81hGVHZ41"
      },
      "source": [
        "classes_list = df_train.emotion.unique().tolist()\n",
        "df_train[\"class\"]=df_train['emotion'].apply(classes_list.index)\n",
        "#df_test[\"class\"]=df_test['emotion'].apply(classes_list.index)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV8812OU9GaD"
      },
      "source": [
        "# ***Preprocessing Functions***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI4fxCud9moQ"
      },
      "source": [
        "Expanding Contractions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klvUPYGNvcOW"
      },
      "source": [
        "import re\n",
        "#########Contraction List#####\n",
        "cList = {\"ain't\": \"am not\",\"aren't\": \"are not\",\"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'cause\": \"because\",\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\"he'll've\": \"he will have\",\n",
        "\"he's\": \"he is\",\"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how is\",\"I'd\": \"I would\",\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\"isn't\": \"is not\",\"it'd\": \"it had\",\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\"it'll've\": \"it will have\",\"it's\": \"it is\",\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\"shan't've\": \"shall not have\",\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\"she's\": \"she is\",\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"so's\": \"so is\",\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\"that's\": \"that is\",\"there'd\": \"there had\",\"there'd've\": \"there would have\",\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we had\",\"we'd've\": \"we would have\",\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\"weren't\": \"were not\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\"what's\": \"what is\",\"what've\": \"what have\",\"when's\": \"when is\",\"when've\": \"when have\",\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who's\": \"who is\",\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\"y'alls\": \"you alls\",\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you had\",\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you you will\",\"you'll've\": \"you you will have\",\"you're\": \"you are\",\"you've\": \"you have\"}\n",
        "#########Function for contraction#####\n",
        "c_re = re.compile('(%s)' % '|'.join(cList.keys())) #regular expression object, with format of contractions like i'm, i've\n",
        "def expandContractions(text, c_re=c_re):\n",
        "    def replace(match):\n",
        "        return cList[match.group(0)] #find the match in the list\n",
        "    return c_re.sub(replace, text)  #replacing the short hands with expanded version"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNIcTaiy91Kq"
      },
      "source": [
        "Lemmatization according to sentence structure "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Maa-nAu97qF",
        "outputId": "400233ea-301f-4906-f196-793c162caa26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb0sMADs8Qi2"
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "lemma_function = WordNetLemmatizer()\n",
        "def lemmatize(row):\n",
        "  tokens = word_tokenize(row)\n",
        "  new =  \"\"\n",
        "  for token, tag in pos_tag(tokens):\n",
        "    if token not in stopwords.words('english'):\n",
        "      lemma = lemma_function.lemmatize(token, tag_map[tag[0]])\n",
        "      new=new+lemma+\" \"\n",
        "  return new"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I75gg3gwo8qh",
        "outputId": "e43b87fe-7f0f-4cfe-b33a-8f26279a51b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPfEpo8v9_lA"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "491detyu-lD2"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from nltk.corpus import stopwords\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(\"@\",\"username\") #removing @\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(\"'s\",\"\")\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(\"?\",\" question \")\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(\"!\",\" exclamation \")\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(r'http\\S+', '')# removing links\n",
        "df_train[\"text\"]=df_train[\"text\"].apply(expandContractions) #expanding contractions\n",
        "df_train[\"text\"]=df_train[\"text\"].apply(emoji.demojize)#changing emojis to text\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(\"#\",\"\").str.replace(\"_\",\" \").str.replace(\":\",\" \").str.lower()\n",
        "df_train[\"text\"]=df_train[\"text\"].apply(lemmatize) #lemmatization\n",
        "df_train[\"text\"]=df_train[\"text\"].str.replace(r'[^\\w\\s]',\" \") #removing punctuation\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(\"@\",\"username\")\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(\"'s\",\"\")\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(\"?\",\" question \")\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(\"!\",\" exclamation \")\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(r'http\\S+', '')\n",
        "df_test[\"text\"]=df_test[\"text\"].apply(expandContractions)\n",
        "df_test[\"text\"]=df_test[\"text\"].apply(emoji.demojize)\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(\"#\",\"\").str.replace(\"_\",\" \").str.replace(\":\",\"\").str.lower()\n",
        "df_test[\"text\"]=df_test[\"text\"].apply(lemmatize)\n",
        "df_test[\"text\"]=df_test[\"text\"].str.replace(r'[^\\w\\s]',\"\")\n",
        "tokenizer = Tokenizer(num_words=5000) # tokenizing\n",
        "tokenizer.fit_on_texts(df_train[\"text\"].values.tolist())\n",
        "#Creating the training and testing sets consisting of tokens\n",
        "X_train = tokenizer.texts_to_sequences(df_train[\"text\"].values.tolist())\n",
        "X_test = tokenizer.texts_to_sequences(df_test[\"text\"].values.tolist())\n",
        "vocab_size = len(tokenizer.word_index) + 1 \n",
        "word_index=tokenizer.word_index"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJZ_S138dfF1",
        "outputId": "9590940c-09fd-49ac-8e96-451becb985f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(word_index)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQCfykSh_QRt"
      },
      "source": [
        "Preparing the training and testing sets for Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhzvBMmtKV4U"
      },
      "source": [
        "maxlen=max([len(a) for a in X_train])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_OppxtnV0iI"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyZP2TN8L0bI"
      },
      "source": [
        "y_train=df_train[\"class\"].values.tolist()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhBYHZul-05p"
      },
      "source": [
        "# **Function for Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEMjJ8TcSxpv"
      },
      "source": [
        "import numpy as np\n",
        "def make_glovevec(glovepath, max_features, embed_size, word_index, veclen=300):\n",
        "    embeddings_index = {}\n",
        "    f = open(glovepath)\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        dimension=len(values)-1\n",
        "        word = ' '.join(values[:-300])\n",
        "        coefs = np.asarray(values[-300:], dtype='float32')\n",
        "        embeddings_index[word] = coefs.reshape(-1)\n",
        "    f.close()\n",
        "\n",
        "    nb_words = min(max_features, len(word_index)+1)\n",
        "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gRAxVSSaSC2",
        "outputId": "f8b7d0f5-2d9c-45c2-e16d-553ff1d66f68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEKYaseJaLm9"
      },
      "source": [
        "max_features=len(word_index)\n",
        "embed_size=300\n",
        "embedding_vector = make_glovevec(\"/content/drive/My Drive/glove.840B.300d.txt\", max_features+1, embed_size, word_index)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO6upg0n_fIK"
      },
      "source": [
        "# The Classifiers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0UksjuIcR5F"
      },
      "source": [
        " ############### Keras\n",
        "from keras.models import Sequential\n",
        "from keras_self_attention import SeqSelfAttention as Attention\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPwYa0d9hHVi",
        "outputId": "2b822584-1948-4c6e-dae0-15383b18bb93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibQCjPwtn6NB",
        "outputId": "394f48be-16ba-4ea4-fbd7-67ad3ac46331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "#################BiLSTM Attention+ Relu without any dropouts ######################\n",
        "d2=0.0\n",
        "d1=0.0\n",
        "class_weight=class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(len(word_index)+1, 300, input_length=77, weights=[embedding_vector], trainable=False))\n",
        "model_glove.add(Bidirectional(LSTM(300, return_sequences=True, dropout=d1,recurrent_dropout=d2)))\n",
        "#model_glove.add(Attention(attention_activation='sigmoid'))\n",
        "#model_glove.add(Flatten())\n",
        "model_glove.add(Dense(10, activation='relu'))\n",
        "model_glove.add(Flatten())\n",
        "#model_glove.add(Dropout(0.0)) \n",
        "model_glove.add(Dense(7, activation='softmax'))\n",
        "#model_glove.add(Flatten())\n",
        "opt = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "model_glove.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model_glove.summary()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_33 (Embedding)     (None, 77, 300)           2054400   \n",
            "_________________________________________________________________\n",
            "bidirectional_32 (Bidirectio (None, 77, 600)           1442400   \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 77, 10)            6010      \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 770)               0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 7)                 5397      \n",
            "=================================================================\n",
            "Total params: 3,508,207\n",
            "Trainable params: 1,453,807\n",
            "Non-trainable params: 2,054,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-zyn5-gotMm",
        "outputId": "74b43ca8-3f05-4f82-f97b-ab7096a0cba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_binary = to_categorical(y_train)\n",
        "model_glove.fit(X_train, y_binary, epochs =15)#,class_weight = class_weight)#,sample_weight=sample_weight)\n",
        "model_glove.summary()\n",
        "y_test=df_test[\"class\"].values.tolist()\n",
        "#y_pred= model_glove.predict_classes(X_test)\n",
        "y_pred= np.argmax(model_glove.predict(X_train),axis=-1)\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))   \n",
        "confusion_matrix(y_test, y_pred)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            " 25/235 [==>...........................] - ETA: 2:19 - loss: 1.9466 - accuracy: 0.1325"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaL1RVoxy56k",
        "outputId": "f5b937fc-5294-42ee-e441-0b1f1bfb5338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred= np.argmax(model_glove.predict(X_train),axis=-1)\n",
        "print(\"Accuracy score =\", accuracy_score(y_train, y_pred))\n",
        "print(metrics.classification_report(y_train, y_pred))   \n",
        "confusion_matrix(y_train, y_pred)   "
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score = 0.5288717402873869\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.79      0.64      1092\n",
            "           1       0.62      0.69      0.65      1076\n",
            "           2       0.48      0.33      0.39      1079\n",
            "           3       0.56      0.58      0.57      1082\n",
            "           4       0.52      0.57      0.54      1066\n",
            "           5       0.46      0.39      0.42      1071\n",
            "           6       0.48      0.35      0.41      1050\n",
            "\n",
            "    accuracy                           0.53      7516\n",
            "   macro avg       0.52      0.53      0.52      7516\n",
            "weighted avg       0.52      0.53      0.52      7516\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[860,  24,  17, 111,  10,  51,  19],\n",
              "       [ 69, 739,  41,  89,  82,  22,  34],\n",
              "       [111,  88, 354,  70, 180, 137, 139],\n",
              "       [216,  86,  28, 624,  26,  43,  59],\n",
              "       [ 75,  83,  91,  47, 606, 114,  50],\n",
              "       [147,  69,  92,  57, 181, 422, 103],\n",
              "       [133, 105, 122, 110,  78, 132, 370]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUz-lQpA-SSI",
        "outputId": "4cb0831b-c987-48a1-fc0a-5059a86ad61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "source": [
        "#################BiLSTM Attention+ Relu without any dropouts ######################\n",
        "d2=0.0\n",
        "d1=0.0\n",
        "y_train=np.array(y_train)\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(len(word_index)+1, 300, input_length=77, weights=[embedding_vector], trainable=False))\n",
        "model_glove.add(Bidirectional(LSTM(300, return_sequences=True, dropout=d1,recurrent_dropout=d2)))\n",
        "model_glove.add(Attention(attention_activation='sigmoid'))\n",
        "#model_glove.add(Flatten())\n",
        "#model_glove.add(Dense(10, activation='relu'))\n",
        "#model_glove.add(Dropout(0.0)) \n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## Fit train data\n",
        "model_glove.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "from keras.utils import to_categorical\n",
        "y_binary = to_categorical(y_train)\n",
        "model_glove.fit(X_train, y_binary, epochs =25)#,class_weight = class_weight)#,sample_weight=sample_weight)\n",
        "#model_glove.fit(X_train, y_train, validation_split=0.2, epochs = 10)\n",
        "y_pred= model_glove.predict_classes(X_test)\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))   \n",
        "confusion_matrix(y_test, y_pred)   "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-c07a81e87f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0my_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel_glove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,class_weight = class_weight)#,sample_weight=sample_weight)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#model_glove.fit(X_train, y_train, validation_split=0.2, epochs = 10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_glove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [32,77] vs. [32,7]\n\t [[node Equal (defined at <ipython-input-53-c07a81e87f0f>:18) ]] [Op:__inference_train_function_49461]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R1ZlHqo73ej"
      },
      "source": [
        "# **Extras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2r8KRlyO3Zn",
        "outputId": "de65e2ac-1034-46de-b596-d20e954ad8f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "#################BiLSTM Attention without any dropouts ######################\n",
        "d2=0.0\n",
        "d1=0.0\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(len(word_index)+1, 300, input_length=129, weights=[embedding_vector], trainable=False))\n",
        "model_glove.add(Bidirectional(LSTM(300, return_sequences=True, dropout=d1,recurrent_dropout=d2)))\n",
        "model_glove.add(Attention(attention_activation='sigmoid'))\n",
        "model_glove.add(Flatten())\n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## Fit train data\n",
        "model_glove.fit(X_train, y_train, validation_split=0.2, epochs = 10)\n",
        "y_pred = model_glove.predict_classes(X_test)\n",
        "y_test=df_test[\"class\"].values.tolist()\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4681 samples, validate on 1171 samples\n",
            "Epoch 1/10\n",
            "4681/4681 [==============================] - 254s 54ms/step - loss: 0.5797 - accuracy: 0.7090 - val_loss: 0.9242 - val_accuracy: 0.4142\n",
            "Epoch 2/10\n",
            "4681/4681 [==============================] - 243s 52ms/step - loss: 0.5352 - accuracy: 0.7419 - val_loss: 0.9968 - val_accuracy: 0.3749\n",
            "Epoch 3/10\n",
            "4681/4681 [==============================] - 248s 53ms/step - loss: 0.5158 - accuracy: 0.7601 - val_loss: 0.9396 - val_accuracy: 0.4031\n",
            "Epoch 4/10\n",
            "4681/4681 [==============================] - 243s 52ms/step - loss: 0.5003 - accuracy: 0.7631 - val_loss: 1.2389 - val_accuracy: 0.3723\n",
            "Epoch 5/10\n",
            "4681/4681 [==============================] - 239s 51ms/step - loss: 0.4740 - accuracy: 0.7746 - val_loss: 1.1495 - val_accuracy: 0.3749\n",
            "Epoch 6/10\n",
            "4681/4681 [==============================] - 223s 48ms/step - loss: 0.4344 - accuracy: 0.7934 - val_loss: 1.2238 - val_accuracy: 0.4082\n",
            "Epoch 7/10\n",
            "4681/4681 [==============================] - 222s 47ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 1.2246 - val_accuracy: 0.4065\n",
            "Epoch 8/10\n",
            "4681/4681 [==============================] - 226s 48ms/step - loss: 0.3500 - accuracy: 0.8543 - val_loss: 1.2034 - val_accuracy: 0.4731\n",
            "Epoch 9/10\n",
            "4681/4681 [==============================] - 225s 48ms/step - loss: 0.3058 - accuracy: 0.8654 - val_loss: 1.6081 - val_accuracy: 0.4791\n",
            "Epoch 10/10\n",
            "4681/4681 [==============================] - 225s 48ms/step - loss: 0.2373 - accuracy: 0.9056 - val_loss: 2.1764 - val_accuracy: 0.4372\n",
            "Accuracy score = 0.8091934084995663\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.88       865\n",
            "           1       0.64      0.53      0.58       288\n",
            "\n",
            "    accuracy                           0.81      1153\n",
            "   macro avg       0.75      0.72      0.73      1153\n",
            "weighted avg       0.80      0.81      0.80      1153\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_o_JNSMa4or",
        "outputId": "30bd58f5-2c84-48bb-ca8c-c63bfa8e0af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#################BiLSTM Attention Dropouts-0.2,0.1,0.05######################\n",
        "d2=0.2\n",
        "d1=0.1\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(len(word_index)+1, 300, input_length=129, weights=[embedding_vector], trainable=False))\n",
        "model_glove.add(Bidirectional(LSTM(300, return_sequences=True, dropout=d1,recurrent_dropout=d2)))\n",
        "model_glove.add(Attention(attention_activation='sigmoid'))\n",
        "model_glove.add(Flatten())\n",
        "model_glove.add(Dense(10, activation='relu'))\n",
        "model_glove.add(Dropout(0.05)) \n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## Fit train data\n",
        "model_glove.fit(X_train, y_train, validation_split=0.2, epochs = 6)\n",
        "y_pred = model_glove.predict_classes(X_test)\n",
        "y_test=df_test[\"class\"].values.tolist()\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4681 samples, validate on 1171 samples\n",
            "Epoch 1/6\n",
            "4681/4681 [==============================] - 229s 49ms/step - loss: 0.5881 - accuracy: 0.7125 - val_loss: 0.8163 - val_accuracy: 0.4910\n",
            "Epoch 2/6\n",
            "4681/4681 [==============================] - 228s 49ms/step - loss: 0.5437 - accuracy: 0.7349 - val_loss: 0.9642 - val_accuracy: 0.3860\n",
            "Epoch 3/6\n",
            "4681/4681 [==============================] - 232s 49ms/step - loss: 0.5263 - accuracy: 0.7424 - val_loss: 0.9707 - val_accuracy: 0.4039\n",
            "Epoch 4/6\n",
            "4681/4681 [==============================] - 232s 50ms/step - loss: 0.5143 - accuracy: 0.7535 - val_loss: 1.1224 - val_accuracy: 0.3775\n",
            "Epoch 5/6\n",
            "4681/4681 [==============================] - 229s 49ms/step - loss: 0.5039 - accuracy: 0.7571 - val_loss: 1.0750 - val_accuracy: 0.3424\n",
            "Epoch 6/6\n",
            "4681/4681 [==============================] - 233s 50ms/step - loss: 0.4827 - accuracy: 0.7695 - val_loss: 0.8940 - val_accuracy: 0.3834\n",
            "Accuracy score = 0.8230702515177797\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89       865\n",
            "           1       0.74      0.44      0.56       288\n",
            "\n",
            "    accuracy                           0.82      1153\n",
            "   macro avg       0.79      0.70      0.72      1153\n",
            "weighted avg       0.81      0.82      0.81      1153\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4Hsr7qrruyT",
        "outputId": "318c360a-34d2-4599-dede-84fdfd8910c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#################BiLSTM Attention Dropouts-0.2,0.1,0.05######################\n",
        "d2=0.0\n",
        "d1=0.0\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(len(word_index)+1, 300, input_length=129, weights=[embedding_vector], trainable=False))\n",
        "model_glove.add(Bidirectional(LSTM(300, return_sequences=True, dropout=d1,recurrent_dropout=d2)))\n",
        "model_glove.add(Attention(attention_activation='sigmoid'))\n",
        "model_glove.add(Flatten())\n",
        "#model_glove.add(Dense(10, activation='relu'))\n",
        "#model_glove.add(Dropout(0.05)) \n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## Fit train data\n",
        "model_glove.fit(X_train, y_train, validation_split=0.2, epochs = 6)\n",
        "y_pred = model_glove.predict_classes(X_test)\n",
        "y_test=df_test[\"class\"].values.tolist()\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4681 samples, validate on 1171 samples\n",
            "Epoch 1/6\n",
            "4681/4681 [==============================] - 227s 48ms/step - loss: 0.5773 - accuracy: 0.7223 - val_loss: 0.9363 - val_accuracy: 0.3817\n",
            "Epoch 2/6\n",
            "4681/4681 [==============================] - 234s 50ms/step - loss: 0.5351 - accuracy: 0.7454 - val_loss: 0.9259 - val_accuracy: 0.3945\n",
            "Epoch 3/6\n",
            "4681/4681 [==============================] - 228s 49ms/step - loss: 0.5169 - accuracy: 0.7550 - val_loss: 1.1660 - val_accuracy: 0.3621\n",
            "Epoch 4/6\n",
            "4681/4681 [==============================] - 227s 48ms/step - loss: 0.5041 - accuracy: 0.7631 - val_loss: 1.0445 - val_accuracy: 0.4082\n",
            "Epoch 5/6\n",
            "4681/4681 [==============================] - 228s 49ms/step - loss: 0.4717 - accuracy: 0.7791 - val_loss: 1.0439 - val_accuracy: 0.3945\n",
            "Epoch 6/6\n",
            "4681/4681 [==============================] - 226s 48ms/step - loss: 0.4452 - accuracy: 0.7973 - val_loss: 1.0614 - val_accuracy: 0.4022\n",
            "Accuracy score = 0.8100607111882047\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.88       865\n",
            "           1       0.69      0.44      0.54       288\n",
            "\n",
            "    accuracy                           0.81      1153\n",
            "   macro avg       0.76      0.69      0.71      1153\n",
            "weighted avg       0.80      0.81      0.79      1153\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqHQ4CytobwH",
        "outputId": "cef493d4-dff5-4f3d-cfb4-0eafb361b42e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[808,  57],\n",
              "       [162, 126]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuCLPSWLHtv3",
        "outputId": "476a97b7-73b1-4104-c2c0-daae348e6ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "d2=0.2\n",
        "d1=0.25\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(len(word_index)+1, 300, input_length=129, weights=[embedding_vector], trainable=False))\n",
        "model_glove.add(Bidirectional(LSTM(300, return_sequences=True, dropout=d1,recurrent_dropout=d2)))\n",
        "model_glove.add(Attention(attention_activation='sigmoid'))\n",
        "model_glove.add(Flatten())\n",
        "model_glove.add(Dense(10, activation='relu'))\n",
        "model_glove.add(Dropout(0.1)) \n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## Fit train data\n",
        "model_glove.fit(X_train, y_train, validation_split=0.2, epochs = 5)\n",
        "y_pred = model_glove.predict_classes(X_test)\n",
        "y_test=df_test[\"class\"].values.tolist()\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4681 samples, validate on 1171 samples\n",
            "Epoch 1/5\n",
            "4681/4681 [==============================] - 231s 49ms/step - loss: 0.5899 - accuracy: 0.7020 - val_loss: 0.9900 - val_accuracy: 0.2921\n",
            "Epoch 2/5\n",
            "4681/4681 [==============================] - 231s 49ms/step - loss: 0.5516 - accuracy: 0.7272 - val_loss: 0.9772 - val_accuracy: 0.3348\n",
            "Epoch 3/5\n",
            "4681/4681 [==============================] - 230s 49ms/step - loss: 0.5423 - accuracy: 0.7278 - val_loss: 1.0722 - val_accuracy: 0.3091\n",
            "Epoch 4/5\n",
            "4681/4681 [==============================] - 232s 50ms/step - loss: 0.5313 - accuracy: 0.7432 - val_loss: 0.9881 - val_accuracy: 0.3365\n",
            "Epoch 5/5\n",
            "4681/4681 [==============================] - 231s 49ms/step - loss: 0.5206 - accuracy: 0.7398 - val_loss: 0.9451 - val_accuracy: 0.3766\n",
            "Accuracy score = 0.8074588031222897\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.88       865\n",
            "           1       0.77      0.33      0.46       288\n",
            "\n",
            "    accuracy                           0.81      1153\n",
            "   macro avg       0.79      0.65      0.67      1153\n",
            "weighted avg       0.80      0.81      0.78      1153\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1H22UCf6Ept",
        "outputId": "cec1da93-3c3f-4ec6-9e8e-8bb17f5ddd55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "##########LSTM+CNN-Modified features#########\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(len(word_index)+1, 300, input_length=129, weights=[embedding_vector], trainable=False))\n",
        "model_glove.add(Conv1D(32, 5, activation='relu'))\n",
        "model_glove.add(MaxPooling1D(pool_size=4))\n",
        "model_glove.add(LSTM(300, return_sequences=True))#, dropout=0.05,recurrent_dropout=0.05))\n",
        "model_glove.add(Flatten())\n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## Fit train data\n",
        "y_train=df_train[\"class\"].values.tolist()\n",
        "model_glove.fit(X_train, y_train, validation_split=0.2, epochs = 5)\n",
        "y_pred = model_glove.predict_classes(X_test)\n",
        "y_test=df_test[\"class\"].values.tolist()\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))      \n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4681 samples, validate on 1171 samples\n",
            "Epoch 1/5\n",
            "4681/4681 [==============================] - 24s 5ms/step - loss: 0.5761 - accuracy: 0.7127 - val_loss: 0.8851 - val_accuracy: 0.3740\n",
            "Epoch 2/5\n",
            "4681/4681 [==============================] - 24s 5ms/step - loss: 0.5030 - accuracy: 0.7620 - val_loss: 1.1924 - val_accuracy: 0.3595\n",
            "Epoch 3/5\n",
            "4681/4681 [==============================] - 24s 5ms/step - loss: 0.4316 - accuracy: 0.8097 - val_loss: 1.0580 - val_accuracy: 0.4048\n",
            "Epoch 4/5\n",
            "4681/4681 [==============================] - 23s 5ms/step - loss: 0.3197 - accuracy: 0.8705 - val_loss: 0.9961 - val_accuracy: 0.5260\n",
            "Epoch 5/5\n",
            "4681/4681 [==============================] - 24s 5ms/step - loss: 0.2326 - accuracy: 0.9124 - val_loss: 1.5197 - val_accuracy: 0.4663\n",
            "Accuracy score = 0.779705117085863\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.84      0.85       865\n",
            "           1       0.55      0.61      0.58       288\n",
            "\n",
            "    accuracy                           0.78      1153\n",
            "   macro avg       0.71      0.72      0.72      1153\n",
            "weighted avg       0.79      0.78      0.78      1153\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[724, 141],\n",
              "       [113, 175]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llXpP1ZBlxj2",
        "outputId": "15f1540d-1fed-4777-85c4-4cdee1f63dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "##########LSTM+CNN-Modified features#########\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(len(word_index)+1, 300, input_length=129, weights=[embedding_vector], trainable=False))\n",
        "model_glove.add(Conv1D(32, 5, activation='relu'))\n",
        "model_glove.add(MaxPooling1D(pool_size=4))\n",
        "model_glove.add(LSTM(300, return_sequences=True, dropout=0.2,recurrent_dropout=0.1))\n",
        "model_glove.add(Flatten())\n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## Fit train data\n",
        "y_train=df_train[\"class\"].values.tolist()\n",
        "model_glove.fit(X_train, y_train, validation_split=0.2, epochs = 5)\n",
        "y_pred = model_glove.predict_classes(X_test)\n",
        "y_test=df_test[\"class\"].values.tolist()\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))      \n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4681 samples, validate on 1171 samples\n",
            "Epoch 1/5\n",
            "4681/4681 [==============================] - 25s 5ms/step - loss: 0.5828 - accuracy: 0.7112 - val_loss: 0.8565 - val_accuracy: 0.3860\n",
            "Epoch 2/5\n",
            "4681/4681 [==============================] - 24s 5ms/step - loss: 0.5265 - accuracy: 0.7477 - val_loss: 0.9039 - val_accuracy: 0.4253\n",
            "Epoch 3/5\n",
            "4681/4681 [==============================] - 24s 5ms/step - loss: 0.4708 - accuracy: 0.7787 - val_loss: 0.8216 - val_accuracy: 0.4586\n",
            "Epoch 4/5\n",
            "4681/4681 [==============================] - 24s 5ms/step - loss: 0.4101 - accuracy: 0.8088 - val_loss: 1.0679 - val_accuracy: 0.4330\n",
            "Epoch 5/5\n",
            "4681/4681 [==============================] - 24s 5ms/step - loss: 0.3473 - accuracy: 0.8541 - val_loss: 1.0971 - val_accuracy: 0.4492\n",
            "Accuracy score = 0.7623590633130962\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84       865\n",
            "           1       0.52      0.54      0.53       288\n",
            "\n",
            "    accuracy                           0.76      1153\n",
            "   macro avg       0.68      0.69      0.69      1153\n",
            "weighted avg       0.77      0.76      0.76      1153\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[723, 142],\n",
              "       [132, 156]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZTL06joQcRf",
        "outputId": "3a5a0fee-d972-4f25-b4df-90b959968286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "#################BiLSTM Attention+ Relu without any dropouts ######################\n",
        "d2=0.0\n",
        "d1=0.0\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(len(word_index)+1, 300, input_length=129, weights=[embedding_vector], trainable=False))\n",
        "model_glove.add(Bidirectional(LSTM(300, return_sequences=True, dropout=d1,recurrent_dropout=d2)))\n",
        "model_glove.add(Attention(attention_activation='sigmoid'))\n",
        "model_glove.add(Flatten())\n",
        "model_glove.add(Dense(10, activation='relu'))\n",
        "model_glove.add(Dropout(0.0)) \n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## Fit train data\n",
        "model_glove.fit(X_train, y_train, validation_split=0.2, epochs = 7)\n",
        "y_pred = model_glove.predict_classes(X_test)\n",
        "y_test=df_test[\"class\"].values.tolist()\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))   \n",
        "confusion_matrix(y_test, y_pred)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4681 samples, validate on 1171 samples\n",
            "Epoch 1/7\n",
            "4681/4681 [==============================] - 227s 48ms/step - loss: 0.5802 - accuracy: 0.7131 - val_loss: 1.0040 - val_accuracy: 0.3279\n",
            "Epoch 2/7\n",
            "4681/4681 [==============================] - 224s 48ms/step - loss: 0.5375 - accuracy: 0.7347 - val_loss: 1.0232 - val_accuracy: 0.3587\n",
            "Epoch 3/7\n",
            "4681/4681 [==============================] - 228s 49ms/step - loss: 0.5145 - accuracy: 0.7477 - val_loss: 0.9048 - val_accuracy: 0.3416\n",
            "Epoch 4/7\n",
            "4681/4681 [==============================] - 223s 48ms/step - loss: 0.5021 - accuracy: 0.7539 - val_loss: 0.9867 - val_accuracy: 0.3757\n",
            "Epoch 5/7\n",
            "4681/4681 [==============================] - 225s 48ms/step - loss: 0.4772 - accuracy: 0.7742 - val_loss: 1.2079 - val_accuracy: 0.3621\n",
            "Epoch 6/7\n",
            "4681/4681 [==============================] - 227s 48ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 1.0818 - val_accuracy: 0.4278\n",
            "Epoch 7/7\n",
            "4681/4681 [==============================] - 225s 48ms/step - loss: 0.4299 - accuracy: 0.7979 - val_loss: 0.9666 - val_accuracy: 0.4270\n",
            "Accuracy score = 0.813529921942758\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88       865\n",
            "           1       0.67      0.51      0.58       288\n",
            "\n",
            "    accuracy                           0.81      1153\n",
            "   macro avg       0.76      0.71      0.73      1153\n",
            "weighted avg       0.80      0.81      0.80      1153\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[792,  73],\n",
              "       [142, 146]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pgq7Zl1VvnW",
        "outputId": "9d3c78ec-9a6e-4998-b0dd-2604ffdc4cb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "#################BiLSTM Attention Dropouts-0.2,0.05,0.05######################\n",
        "d2=0.2\n",
        "d1=0.05\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(len(word_index)+1, 300, input_length=129, weights=[embedding_vector], trainable=False))\n",
        "model_glove.add(Bidirectional(LSTM(300, return_sequences=True, dropout=d1,recurrent_dropout=d2)))\n",
        "model_glove.add(Attention(attention_activation='sigmoid'))\n",
        "model_glove.add(Flatten())\n",
        "model_glove.add(Dense(10, activation='relu'))\n",
        "model_glove.add(Dropout(0.05)) \n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "## Fit train data\n",
        "model_glove.fit(X_train, y_train, validation_split=0.2, epochs = 10)\n",
        "y_pred = model_glove.predict_classes(X_test)\n",
        "y_test=df_test[\"class\"].values.tolist()\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4681 samples, validate on 1171 samples\n",
            "Epoch 1/10\n",
            "4681/4681 [==============================] - 230s 49ms/step - loss: 0.5960 - accuracy: 0.6981 - val_loss: 0.9824 - val_accuracy: 0.3493\n",
            "Epoch 2/10\n",
            "4681/4681 [==============================] - 230s 49ms/step - loss: 0.5566 - accuracy: 0.7052 - val_loss: 1.0724 - val_accuracy: 0.2750\n",
            "Epoch 3/10\n",
            "4681/4681 [==============================] - 229s 49ms/step - loss: 0.5398 - accuracy: 0.6984 - val_loss: 0.9643 - val_accuracy: 0.2750\n",
            "Epoch 4/10\n",
            "4681/4681 [==============================] - 233s 50ms/step - loss: 0.5330 - accuracy: 0.7287 - val_loss: 0.9721 - val_accuracy: 0.4620\n",
            "Epoch 5/10\n",
            "4681/4681 [==============================] - 231s 49ms/step - loss: 0.5103 - accuracy: 0.7537 - val_loss: 0.8975 - val_accuracy: 0.4330\n",
            "Epoch 6/10\n",
            "4681/4681 [==============================] - 230s 49ms/step - loss: 0.4850 - accuracy: 0.7695 - val_loss: 1.0904 - val_accuracy: 0.4535\n",
            "Epoch 7/10\n",
            "4681/4681 [==============================] - 232s 50ms/step - loss: 0.4650 - accuracy: 0.7840 - val_loss: 0.9808 - val_accuracy: 0.4833\n",
            "Epoch 8/10\n",
            "4681/4681 [==============================] - 230s 49ms/step - loss: 0.4332 - accuracy: 0.8007 - val_loss: 1.0952 - val_accuracy: 0.4372\n",
            "Epoch 9/10\n",
            "4681/4681 [==============================] - 231s 49ms/step - loss: 0.4066 - accuracy: 0.8169 - val_loss: 1.0710 - val_accuracy: 0.4441\n",
            "Epoch 10/10\n",
            "4681/4681 [==============================] - 236s 50ms/step - loss: 0.3712 - accuracy: 0.8374 - val_loss: 1.4450 - val_accuracy: 0.4424\n",
            "Accuracy score = 0.7987857762359063\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.86       865\n",
            "           1       0.59      0.62      0.61       288\n",
            "\n",
            "    accuracy                           0.80      1153\n",
            "   macro avg       0.73      0.74      0.74      1153\n",
            "weighted avg       0.80      0.80      0.80      1153\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu-ukRx_Vyaw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}